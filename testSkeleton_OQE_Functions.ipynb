{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47a8c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pylab as plt\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import mode\n",
    "from scipy.signal.windows import blackmanharris as BH\n",
    "import scipy as sp\n",
    "from multiprocess import Pool\n",
    "from astropy.timeseries import LombScargle as LSc\n",
    "from scipy.signal import lombscargle as lsc\n",
    "conjgrad = sp.sparse.linalg.cg # conjugate gradient solver\n",
    "nsample = np.random.multivariate_normal\n",
    "from scipy.optimize import minimize, Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "845fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(arr):\n",
    "    return np.fft.fftshift(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "466e7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOp(s):\n",
    "    \n",
    "    # basic Fourier operator for matrix side length s\n",
    "    \n",
    "    FO = np.zeros((s,s), dtype=complex)\n",
    "    for i in range(s):\n",
    "        y = np.zeros(s)\n",
    "        y[i] = 1\n",
    "        FO[i] = np.fft.fft(y)\n",
    "        \n",
    "    return FO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff2beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m(tau, s):\n",
    "\n",
    "    y = np.zeros(s)\n",
    "    y[tau] = 1\n",
    "    return np.fft.fft(y)\n",
    "\n",
    "################\n",
    "    \n",
    "def Q(tau, s):\n",
    "    \n",
    "    filename = 'Qs/Q' + str(s) + '_' + str(tau)+ '.npy'\n",
    "    if os.path.isfile(filename):\n",
    "        Q = np.load(filename)\n",
    "    else:\n",
    "        Q = np.outer( m(tau,s).conj(), m(tau,s) )\n",
    "        np.save(filename, Q)\n",
    "    return Q\n",
    "\n",
    "################\n",
    "\n",
    "def bias(tau, s, R, C_noise_total):\n",
    "    \n",
    "    return 0.5 * np.trace( C_noise_total @ R.conj() @ Q(tau,s) @ R )\n",
    "\n",
    "# redundant in HERA setup, but useful for comparison\n",
    "\n",
    "################\n",
    "\n",
    "def qhat(x, tau, s, R, bias):\n",
    "\n",
    "    E = R.conj() @ Q(tau, s) @ R\n",
    "    \n",
    "    return 0.5 *  ( x.conj().T @ E @ x ) - bias\n",
    "\n",
    "def qhat_h(x1, x2, tau, s, R):\n",
    "    # HERA-like cross corr\n",
    "    \n",
    "    # exact Pspec code:\n",
    "#     Rx1, Rx2 = np.dot(R, x1) , np.dot(R, x2)\n",
    "    \n",
    "    \n",
    "#     QRx2 = np.dot(Q(tau,s), Rx2)\n",
    "#     return 0.5 * np.einsum('i...,i...->...', Rx1.conj(), QRx2) # can test these vs each other....\n",
    "    \n",
    "    Rx1, Rx2 = R@x1 , R@x2\n",
    "\n",
    "    return 0.5 * Rx1.conj().T @ Q(tau,s) @ Rx2  \n",
    "                   \n",
    "\n",
    "################\n",
    "\n",
    "def F(s, R):\n",
    "    \n",
    "    t = np.arange(s)\n",
    "    \n",
    "    F = np.zeros((s,s), dtype=complex)\n",
    "    \n",
    "    for a in range(s):\n",
    "        for b in range(s):\n",
    "            F[a,b] = 0.5 * np.trace(  R.conj() @ Q(t[a], s) @ R @ Q(t[b], s)  )\n",
    "    \n",
    "    return F\n",
    "\n",
    "################\n",
    "\n",
    "def Ft(s, R):\n",
    "    \n",
    "    t = np.arange(s)\n",
    "    \n",
    "    F = np.zeros((s,s), dtype=complex)\n",
    "    \n",
    "    iR1Q1, iR2Q2 = {}, {}\n",
    "    \n",
    "    for i in range(s):\n",
    "        iR1Q1[i] = np.dot(np.conj(R).T, Q(i,s)) # R_1 Q_alt\n",
    "        iR2Q2[i] = np.dot(R, Q(i,s)) # R_2 Q\n",
    "    \n",
    "    \n",
    "    for a in range(s):\n",
    "        for b in range(s):\n",
    "            F[a,b] = 0.5*np.einsum('ab,ba', iR1Q1[a], iR2Q2[b])\n",
    "    \n",
    "    return F\n",
    "\n",
    "################\n",
    "\n",
    "def M_Fhalf(F):\n",
    "    \n",
    "    return np.linalg.inv(sp.linalg.sqrtm(F))\n",
    "\n",
    "################\n",
    "\n",
    "def M_Finv(F):\n",
    "    \n",
    "    return np.linalg.inv(F)\n",
    "\n",
    "################\n",
    "\n",
    "def M_opt(F):\n",
    "    \n",
    "    M = np.diag(np.divide(1, np.diag(F)))\n",
    "    W = M @ F\n",
    "    for row in range(0, np.shape(M)[0]):\n",
    "        M[row] = np.divide(M[row], np.sum(W[row])) # Wll normalisation - does it make sense? perhaps not\n",
    "    \n",
    "    return M \n",
    "\n",
    "################\n",
    "\n",
    "def q(V, s, R, bias):\n",
    "    \n",
    "    # calculates qhat across the tau range\n",
    "    # need to calculate bias beforehand - needs to be an array (see return statement below)\n",
    "    \n",
    "    N = len(V)\n",
    "    \n",
    "    t_ = np.arange(s)\n",
    "    \n",
    "    qs = np.zeros((N,s))\n",
    "    \n",
    "    for i in range(N):\n",
    "        qs[i] = np.array([qhat(V[i], tau, s, R, bias[tau]) for tau in t_])\n",
    "    \n",
    "    return qs\n",
    "\n",
    "################\n",
    "\n",
    "def q_h(V, s, R, taper=None):\n",
    "    \n",
    "    N = len(V)//2 # Should be even if creating pairs of visibilities\n",
    "    \n",
    "    t_ = np.arange(s)\n",
    "    \n",
    "    qs = np.zeros((N,s), dtype=complex)\n",
    "\n",
    "    for i in range(N):\n",
    "        qs[i] = np.array([qhat_h(V[2*i], V[2*i+1], t, s, R) for t in t_])\n",
    "    \n",
    "    return qs\n",
    "\n",
    "################\n",
    "\n",
    "def p(q, M):\n",
    "    \n",
    "    return M @ q \n",
    "\n",
    "# def q_h(x1, x2, s, R):\n",
    "#     # old function - keeping in case\n",
    "#     t_ = np.arange(s)\n",
    "#     return np.array([qhat_h(x1, x2, t, s, R) for t in t_])\n",
    "# question - how do HERA do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadedbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pstats(qs, FM, plot=None, ylims=[-2,3.5], xlims=[None, None], scale=None):\n",
    "    \n",
    "    pall_ = flip(np.array([p(q, FM) for q in qs],dtype=complex))\n",
    "\n",
    "    p_ = np.array([np.mean(pall_[:,i]) for i in range(s)])\n",
    "\n",
    "    # std_ = flip([np.std(np.array([p(inprange, q, MB) for q in qs])[:,i]) for i in range(s)])\n",
    "\n",
    "    sp1 = np.array([np.percentile(pall_[:,i], 84.2) for i in range(s)])\n",
    "    sm1 = np.array([np.percentile(pall_[:,i], 15.8) for i in range(s)])\n",
    "    \n",
    "    if (plot=='plot' or plot=='plotonly'):\n",
    "        plt.plot(tau_f, p_, label=r'mean')\n",
    "        plt.fill_between(tau_f, sm1,sp1, alpha=0.25, color='orange')\n",
    "        plt.plot(tau_f, alys, label=r'analytic P($\\tau$)')\n",
    "        plt.title('%d sims + noise + foregrounds'%(N), fontsize=20)\n",
    "        plt.legend(fontsize=14)\n",
    "        plt.xlabel(r'Delay $\\tau$ [$\\mu$s]', fontsize=20)\n",
    "        \n",
    "        if scale=='log':\n",
    "            plt.yscale('log')\n",
    "        plt.xlim(xlims[0],xlims[1])\n",
    "        plt.ylim(ylims[0],ylims[1])\n",
    "        plt.show()\n",
    "        \n",
    "    if plot=='plotonly': return None\n",
    "    else: return pall_, p_, sp1, sm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1b42c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pstats2(qs, FM):\n",
    "    \n",
    "    pall_ = flip(np.array([p(q, FM) for q in qs],dtype=complex))\n",
    "\n",
    "    return pall_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66283605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getqs(Vis, R):\n",
    "    \"\"\"\n",
    "    creates required matrices and runs the skeleton OQE over the given set of data using weighting R,\n",
    "    returning unnormalized qs to be normalized by the pstats function\n",
    "    \n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    s = len(Vis[0])\n",
    "    matc(R)\n",
    "    Fm = F(s, R) # Fisher matrix\n",
    "    MB = M_opt(Fm)\n",
    "    MA = M_Finv(Fm)\n",
    "    qs = q_h(Vis, s, R)\n",
    "    print('%.3fs'%(time.time()-st))\n",
    "    return qs, Fm, MB, MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fa883ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_hp(V, s, R, ncpu):\n",
    "    st=time.time()\n",
    "    N = len(V)//2 \n",
    "    t_ = np.arange(s)\n",
    "    if np.iscomplexobj(V):  qs = np.zeros((N,s), dtype=complex)\n",
    "    else: qs = np.zeros((N,s))\n",
    "        \n",
    "    Vidxs = np.arange(N)\n",
    "    with Pool(ncpu) as pool:\n",
    "        qs = pool.map(lambda idx: np.array([qhat_h(V[2*idx], V[2*idx+1], t, s, R) for t in t_]), Vidxs)\n",
    "    print('%.3fs'%(time.time()-st))\n",
    "    return qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5379ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnoise_c(Vis_sfg, C_noise):\n",
    "    # assumes same covariance for Re and Im noise\n",
    "    N = len(Vis_sfg)\n",
    "    s = len(Vis_sfg[0])\n",
    "    V = np.zeros((2*N,s),dtype=complex)\n",
    "    noise = nsample(mv, C_noise, 4*N)\n",
    "    for i,x in enumerate(Vis_sfg):\n",
    "        V[2*i] , V[2*i+1]  =  x + noise[4*i+0] + 1j*noise[4*i+1], x + noise[4*i+2] + 1j*noise[4*i+3]\n",
    "    return V\n",
    "\n",
    "def addnoise(Vis_sfg, C_noise):\n",
    "    N = len(Vis_sfg)\n",
    "    s = len(Vis_sfg[0])\n",
    "    V = np.zeros((2*N,s))\n",
    "    noise = nsample(mv, C_noise, 2*N)\n",
    "    for i,x in enumerate(Vis_sfg):\n",
    "        V[2*i] , V[2*i+1]  =  x + noise[2*i+0], x + noise[2*i+1]\n",
    "    return V\n",
    "\n",
    "def addnonoise(V):\n",
    "    N = len(V)\n",
    "    Vout = np.zeros((2*N,s),dtype=complex)\n",
    "    for i,x in enumerate(V):\n",
    "        Vout[2*i] , Vout[2*i+1]  =  x , x \n",
    "    return Vout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50f11feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sig_QEN(R, C_noise, norm):\n",
    "    \n",
    "    # In jianrong's paper, E is normalized. So, need to divide by the sum of the (row) of the window function\n",
    "    \n",
    "    s = len(R)\n",
    "    \n",
    "    Sig = np.zeros(s, dtype=complex)\n",
    "    \n",
    "    for i in range(s):\n",
    "        E = R @ Q(i, s) @ R * norm\n",
    "\n",
    "        Sig[i] = 0.5 * np.trace( E @ C_noise @ E @ C_noise )\n",
    "    \n",
    "    return Sig\n",
    "\n",
    "\n",
    "\n",
    "def Sig_QESN(R, C_noise, C_S, norm):\n",
    "    \n",
    "    s = len(R)\n",
    "    \n",
    "    Sig = np.zeros(s, dtype=complex)\n",
    "    \n",
    "    for i in range(s):\n",
    "        E = R @ Q(i, s) @ R * norm\n",
    "        Sig[i] = 0.5 * np.trace( (E @ C_noise @ E @ C_noise) + (E @ C_S @ E @ C_noise) + (E @ C_noise @ E @ C_S))\n",
    "        \n",
    "    \n",
    "    return Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ca8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matc(M):\n",
    "    evs = np.linalg.eigvals(M).real\n",
    "    Minv = np.linalg.inv(M)\n",
    "    print(np.all(evs > 0),' - positive definite')\n",
    "    print(np.format_float_scientific( max(evs)/min(evs)  ),' - eigval ratio')\n",
    "    print('%f'%(np.linalg.norm(M)*np.linalg.norm(Minv)),' - condition (norm C x norm Cinv)')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "13c5a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCR(dat, w, S, N, nrzn=1, inpaint='inpaint', quiet='quiet', dat2=None, bla=None, poolmap=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns a number of constrained realizations for a flagged data vector with signal prior S and noise prior N,\n",
    "    following the Gaussian constrained realization equation. \n",
    "    \n",
    "    Important note: any given realization will not match the data in the unflagged region. If the desire is to\n",
    "    in-paint flagged regions, you will need to select only this region of the output vector.\n",
    "    \n",
    "    ---Variables:\n",
    "    d - Data vector. \n",
    "    w - Flagging/mask vector (1 for unflagged data, 0 for flagged data)\n",
    "    S - Signal prior covariance matrix. Has the same dimension as the data vector. May only be real-valued.   \n",
    "    N - Noise prior covariance matrix. Has the same dimension as the data vector. May only be real-valued.\n",
    "    nrzn - Number of realizations to return.\n",
    "    inpaint - return inpainted mean and realizations. 'inpaint'=on\n",
    "    noisy - Inclusion of cosmetic white noise consistent with N in returned realizations. 'addnoise'=on \n",
    "    ufN - use an unflagged N matrix to find GCR solutions. 'Nunflagged'=on\n",
    "    \n",
    "    \"\"\"\n",
    "    s = len(dat)\n",
    "    d = dat.reshape((1,max(s,len(dat.T))))\n",
    "    nbaselines = 1\n",
    "    if bla is not None:\n",
    "        nbaselines = bla.shape[0] # n_rows (each redundant baseline is one row)\n",
    "        d = np.sum(bla, axis=0).reshape((1,max(len(dat),len(dat.T))))\n",
    "        \n",
    "    if dat2 is not None:\n",
    "        d2 = dat2.reshape((1,max(len(dat2),len(dat2.T))))\n",
    "        d = (d+d2)/2\n",
    "    if np.iscomplexobj(d) or np.iscomplexobj(S) or np.iscomplexobj(N):\n",
    "        dat_complex=True\n",
    "    else: dat_complex=False\n",
    "            \n",
    "    Sh = sp.linalg.sqrtm( S )\n",
    "    Nh = sp.linalg.sqrtm( N )\n",
    "    Si = np.linalg.inv( S )\n",
    "    Ni = w.T*np.linalg.inv( N )*w\n",
    "    Sih = sp.linalg.sqrtm( Si )\n",
    "    Nih = sp.linalg.sqrtm( Ni )\n",
    "           \n",
    "    A = nbaselines*Sh @ Ni @ Sh  + np.eye(s)\n",
    "    Ai = np.linalg.inv(A)\n",
    "    b = Sh @ Ni @ (w*d).T\n",
    "        \n",
    "    wiener, ___ = conjgrad(A, b, maxiter=1e5, M=Ai) # Wiener / max-likelihood solution\n",
    "    Wnr = Sh@wiener\n",
    "    \n",
    "    if dat_complex: solns = np.zeros((nrzn,s), dtype=complex) # array for solutions to GCR equation\n",
    "    else: solns = np.zeros((nrzn,s))\n",
    "    \n",
    "    if not dat_complex:\n",
    "        for i in range(nrzn):\n",
    "            omi = np.random.randn(s,1)\n",
    "            cri = omi + Sh @ Nih @ np.sum(np.random.randn(s,nbaselines),axis=0)\n",
    "   \n",
    "            bcri = b + cri\n",
    "            xboth, info2 = conjgrad(A, bcri, maxiter=1e5, M=Ai)\n",
    "            solns[i] = Sh@xboth\n",
    "                \n",
    "    if dat_complex:\n",
    "        for i in range(nrzn):\n",
    "            omi, omj = np.random.randn(s,1),np.random.randn(s,1)\n",
    "            \n",
    "            cri = (omi+1j*omj)/2**0.5 + Sh @ Nih @ (   np.sum(np.random.randn(s,nbaselines),axis=1)+\\\n",
    "                                                    1j*np.sum(np.random.randn(s,nbaselines),axis=1)   ).reshape((s,1))/2**0.5\n",
    "            \n",
    "            bcri = b + cri\n",
    "            xboth, info2 = conjgrad(A, bcri, maxiter=1e5, M=Ai)\n",
    "            solns[i] = Sh@xboth\n",
    "    \n",
    "    # in-painting if required\n",
    "    \n",
    "    unflagged_indices = np.where(w==1)\n",
    "    if inpaint=='inpaint':\n",
    "        Wnr[unflagged_indices] = dat[unflagged_indices]\n",
    "        for i,sol in enumerate(solns):\n",
    "            solns[i][unflagged_indices] = dat[unflagged_indices]\n",
    "            \n",
    "    if inpaint=='subtract':\n",
    "        Z = np.zeros(s, dtype=complex)\n",
    "        Z[unflagged_indices] = dat[unflagged_indices] - Wnr[unflagged_indices]\n",
    "        Wnr = Z\n",
    "        for i,sol in enumerate(solns):\n",
    "            Z = np.zeros(s, dtype=complex)\n",
    "            Z[unflagged_indices] = dat[unflagged_indices] - sol[unflagged_indices]\n",
    "            solns[i] = Z\n",
    "        \n",
    "    if quiet!='quiet':   print('complex data: ',dat_complex)\n",
    "\n",
    "    if poolmap==True: return solns\n",
    "    else: return Wnr, solns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef2772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # problem cell - do not run\n",
    "\n",
    "# if not dat_complex:\n",
    "#     for i in range(nrzn):\n",
    "#         omi,omj = np.random.randn(120,1), np.random.randn(120,1)\n",
    "#         cri = omi + Sh @ Nih @ omj\n",
    "#         bcri = b + cri\n",
    "#         xboth, info2 = conjgrad(A, bcri, maxiter=1e5, M=Ai)\n",
    "#         solns[i] = Sh@xboth\n",
    "\n",
    "# if dat_complex:\n",
    "#     for i in range(nrzn):\n",
    "#         omi, omj, omk, oml = np.random.randn(120,1),np.random.randn(120,1),np.random.randn(120,1),\\\n",
    "#                                             np.random.randn(120,1)\n",
    "#         cri = (omi+1j*omj) + Sh @ Nih @ (omk+1j*oml)\n",
    "#         bcri = b + cri\n",
    "#         xboth, info2 = conjgrad(A, bcri, maxiter=1e5, M=Ai)\n",
    "#         solns[i] = Sh@xboth \n",
    "        \n",
    "# '''\n",
    "# look at real and imag parts of the power spectrum, rather than abs\n",
    "\n",
    "# seems like...\n",
    "#     cri = (omi+1j*omj) + Sh @ Nih @ (omk+1j*oml) should this be NORM 1? so divide by sqrt 2?????\n",
    "#      or\n",
    "#     conjgrad() might be the culprit?\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d2e2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivePS(data, meansub=1, taper=1):\n",
    "        \n",
    "    if meansub:\n",
    "#         d = d - np.mean(d, axis=0)\n",
    "        d = data - np.mean(data, axis=1)[:,np.newaxis]\n",
    "    \n",
    "    if taper:\n",
    "        d *= BH(s)\n",
    "        \n",
    "    return flip(abs(np.fft.fft(d))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d3203607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nPS(data):\n",
    "    \n",
    "    sk_ = np.fft.fft(data, axis=-1)\n",
    "    \n",
    "    return np.sum(sk_ * sk_.conj(), axis=0).real\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "866615b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCR_OQEarray(V, w, S, N, inpaint='inpaint'):\n",
    "    \n",
    "    VW = np.zeros(V.shape, dtype=complex)\n",
    "    VC = np.zeros(V.shape, dtype=complex)\n",
    "    \n",
    "    for i,rzn in enumerate(V):\n",
    "        if not i%2: \n",
    "            id2=i+1 \n",
    "            wnr, cr = GCR(rzn, w, S, N, nrzn=1, inpaint=inpaint, dat2=V[id2])\n",
    "            VW[i] = wnr\n",
    "            VC[i] = cr\n",
    "            if i==0: print('complex: data',np.iscomplexobj(rzn),'C_s',np.iscomplexobj(S),'C_n',np.iscomplexobj(N))\n",
    "\n",
    "            fi = np.where(w==0)\n",
    "            VW[i+1] = V[i+1]\n",
    "            VC[i+1] = V[i+1]\n",
    "            VW[i+1][fi] = wnr[fi]\n",
    "            VC[i+1][fi] = cr[:,fi]\n",
    "\n",
    "        if not i%100: print(i, end=' ')\n",
    "    return VW, VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bf25acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCR_array(V, w, S, N, inpaint='inpaint', bla=None, ncpu=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    bla set to nbaselines (not None) - take noiseless sims and generate nbaselines \\times noisy sims to hand to the GCR solver\n",
    "    \"\"\"\n",
    "    \n",
    "    VW = np.zeros(V.shape, dtype=complex)\n",
    "    VC = np.zeros(V.shape, dtype=complex)\n",
    "    \n",
    "       \n",
    "    Vidxs = np.arange(V.shape[0])\n",
    "    \n",
    "    st=time.time()\n",
    "    \n",
    "    if bla is None:\n",
    "        \n",
    "        with Pool(ncpu) as pool:\n",
    "            VC = pool.map(lambda idx: GCR(V[idx], w, S, N, nrzn=1, inpaint=inpaint, poolmap=True), Vidxs)\n",
    "\n",
    "#         for i,rzn in enumerate(V):\n",
    "\n",
    "#             wnr, cr = GCR(rzn, w, S, N, nrzn=1, inpaint=inpaint)\n",
    "#             VW[i] = wnr\n",
    "#             VC[i] = cr\n",
    "#             if i==0: print('complex: data',np.iscomplexobj(rzn),'C_s',np.iscomplexobj(S),'C_n',np.iscomplexobj(N))\n",
    "\n",
    "#             if not i%100: print(i, end=' ')\n",
    "                \n",
    "    else:\n",
    "        nbaselines = bla\n",
    "        for i,rzn in enumerate(V): # assuming now that these V are noiseless, we're going to create redundant baseline data here\n",
    "            \n",
    "            noises = nsample(mv, C_noise, nbaselines) + 1j*nsample(mv, C_noise, nbaselines)\n",
    "            redundantbls = rzn + noises # broadcasting single V to nbaselines * noise\n",
    "            \n",
    "            wnr, cr = GCR(rzn, w, S, N, nrzn=1, inpaint=inpaint, bla=redundantbls)\n",
    "            VW[i] = wnr\n",
    "            VC[i] = cr\n",
    "            if i==0: print('complex: data',np.iscomplexobj(rzn),'C_s',np.iscomplexobj(S),'C_n',np.iscomplexobj(N))\n",
    "\n",
    "            if not i%100: print(i, end=' ')\n",
    "    print('%.1fs'%(time.time()-st), end=' ')\n",
    "    return VW, np.array(VC).reshape(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9a590dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCR_eigarray(V, w, S, F_evecs, N, ncpu=2):\n",
    "    \n",
    "    VC = np.zeros(V.shape, dtype=complex)\n",
    "\n",
    "    Vidxs = np.arange(V.shape[0])\n",
    "    \n",
    "    st=time.time()\n",
    "    \n",
    "    with Pool(ncpu) as pool:\n",
    "        VC = pool.map(lambda idx: GCR_eig(V[idx], w, S, F_evecs, N), Vidxs)\n",
    "\n",
    "    print('%.1fs'%(time.time()-st), end=' ')\n",
    "    return np.array(VC).reshape(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af802bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wfcorrection(S,N):\n",
    "    # does this need an fftshift? adding one in the results script\n",
    "    T = np.zeros((s,s), dtype=complex)\n",
    "\n",
    "    for i in range(s):\n",
    "        T[i] = m(i,s)\n",
    "        \n",
    "    return np.diag(T.conj().T @ ( S @ np.linalg.inv(S+N) @ N    ) @ T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41001674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_eb(dat):\n",
    "    # two tailed errorbar\n",
    "    \n",
    "    sp1 = np.array([np.percentile(dat[:,i], 84.2) for i in range(s)])\n",
    "    sm1 = np.array([np.percentile(dat[:,i], 15.8) for i in range(s)])\n",
    "    \n",
    "    return sp1+sm1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20c2a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorr_matrix(w, tau, freqs):\n",
    "    \"\"\"\n",
    "    Calculate rotation matrix from Eq. 8 of Bryna's note, \n",
    "    needed to decorrelate the real and imaginary amplitudes of \n",
    "    the least squares-fitted cosine/sine modes.\n",
    "    \n",
    "    To use this matrix to decorrelate the amplitudes, do:\n",
    "    `np.dot(rot, [A_real, A_imag])`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    w : array_like\n",
    "        Mask vector, 1 for unmasked, 0 for masked.\n",
    "    \n",
    "    tau : float\n",
    "        Delay wavenumber.\n",
    "    \n",
    "    freqs : array_like\n",
    "        Frequency array.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rot : array_like\n",
    "        Rotation matrix to be applied to the amplitude vector.\n",
    "        \n",
    "    eigvals : array_like\n",
    "        Eigenvalues of mode correlation matrix. Multiply the \n",
    "        variance of the mode, sigma^2, with these eigenvalues \n",
    "        to get the new variances (sigma1^2, sigma2^2); see \n",
    "        Eq. 9 of Bryna's note.\n",
    "    \"\"\"\n",
    "    # Sine and cosine terms with mask\n",
    "    cos = w*np.cos(2.*np.pi*tau*freqs)\n",
    "    sin = w*np.sin(2.*np.pi*tau*freqs)\n",
    "    \n",
    "    # Covariance (overlap) matrix\n",
    "    cov = np.zeros((2, 2))\n",
    "    cov[0,0] = np.sum(cos*cos)\n",
    "    cov[0,1] = cov[1,0] = np.sum(cos*sin)\n",
    "    cov[1,1] = np.sum(sin*sin)\n",
    "    \n",
    "    # Calculate rotation angle directly\n",
    "    theta = 0.5 * np.arctan2(2.*np.sum(cos*sin), \n",
    "                             np.sum(cos*cos) - np.sum(sin*sin))\n",
    "    rot = np.array([[np.cos(theta), np.sin(theta)], \n",
    "                     [-np.sin(theta), np.cos(theta)]])\n",
    "    rinv = np.array([[np.cos(theta), -np.sin(theta)], \n",
    "                     [np.sin(theta), np.cos(theta)]])\n",
    "    eigvals = np.diag(np.dot(rot, np.dot(cov, rinv)))\n",
    "    \n",
    "    # Eigendecomposition\n",
    "    #eigvals, eigvec = np.linalg.eig(cov)\n",
    "    \n",
    "    # Rotation operator is inverse of the eigenvector matrix\n",
    "    #rot = np.linalg.pinv(eigvec)\n",
    "    return rot, eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9f1d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorr_pspec(A_re, A_im, w, tau, freqs):\n",
    "    \"\"\"\n",
    "    Calculate the LSSA power spectrum, by using Bryna's decorrelation \n",
    "    scheme to re-weight the real and imaginary amplitudes.\n",
    "    \"\"\"\n",
    "    ps = np.zeros(tau.size)\n",
    "    \n",
    "    # Loop over tau modes\n",
    "    for i, t in enumerate(tau):\n",
    "        # Get decorrelation matrix and eigenvalues\n",
    "        rot, eigvals = decorr_matrix(w=w, tau=t, freqs=freqs)\n",
    "        \n",
    "        # Apply decorrelation rotation\n",
    "        A1, A2 = np.matmul(rot, np.array([A_re[i], A_im[i]]))\n",
    "        \n",
    "        # Construct power spectrum (c.f. Eq. 12 of Bryna's note)\n",
    "        # Multiplied num. and denom. by each eigval squared to avoid 1/0\n",
    "        ps[i] = ((A1 * eigvals[1])**2. + (A2 * eigvals[0])**2.) \\\n",
    "              / (eigvals[0]**2. + eigvals[1]**2.)\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99ca9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ap(amp, phase, tau, freqs):\n",
    "    return amp * np.exp(-2.*np.pi*1.j*tau*freqs + 1.j*phase)\n",
    "\n",
    "def model_aa(A_re, A_im, tau, freqs):\n",
    "    return (A_re + 1.j*A_im) * np.exp(-2.*np.pi*1.j*tau*freqs)\n",
    "\n",
    "def lssa_fit_modes(d, freqs, invcov=None, fit_amp_phase=True, tau=None, \n",
    "                   minimize_method='L-BFGS-B', taper=None):\n",
    "    r\"\"\"\n",
    "    Perform a weighted LSSA fit to masked complex 1D data.\n",
    "\n",
    "    NOTE: The input data/covariance should have already had the flagged \n",
    "    channels removed. Use the `trim_flagged_channels()` function to do \n",
    "    this.\n",
    "    \n",
    "    The log-likelihood for each sinusoid takes the assumed form:\n",
    "    \n",
    "    $\\log L_n = \\tilde{x}^\\dagger \\tilde{C}^{-1} \\tilde{x}$\n",
    "    \n",
    "    where $\\tau_n = n / \\Delta \\nu$, $\\Delta \\nu$ is the bandwidth, and \n",
    "    \n",
    "    $x = [d - A \\exp(2 \\pi i \\nu \\tau_n + i\\phi)]$.\n",
    "\n",
    "    The tilde denotes vectors/matrices from which the masked channels \n",
    "    (rows/columns) have been removed entirely.\n",
    "    \n",
    "    Parameters:\n",
    "        d (array_like):\n",
    "            Complex data array that has already had flagged channels removed.\n",
    "        \n",
    "        freqs (array_like):\n",
    "            Array of frequency values, in MHz. Used to get tau values in \n",
    "            the right units only. Flagged channels must have already been \n",
    "            removed.\n",
    "        \n",
    "        invcov (array_like):\n",
    "            Inverse of the covariance matrix (flagged channels must have been \n",
    "            removed before inverting).\n",
    "\n",
    "        fit_amp_phase (bool, optional):\n",
    "            If True, fits the (real) amplitude and (real) phase parameters \n",
    "            for each sinusoid. If False, fits the real and imaginary amplitudes.\n",
    "        \n",
    "        tau (array_like, optional):\n",
    "            Array of tau modes to fit. If `None`, will use `fftfreq()` to \n",
    "            calculate the tau values. Units: nanosec.\n",
    "        \n",
    "        taper (array_like, optional):\n",
    "            If specified, multiplies the data and sinusoid model by a taper \n",
    "            function to enforce periodicity. The taper should be evaluated \n",
    "            at the locations specified in `freqs`\n",
    "        \n",
    "        minimize_method (str, optional):\n",
    "            Which SciPy minimisation method to use. Default: `'L-BFGS-B'`.\n",
    "    \n",
    "    Returns:\n",
    "        tau (array_like):\n",
    "            Wavenumbers, calculated as tau_n = n / L, in nanoseconds.\n",
    "            \n",
    "        param1, param2 (array_like):\n",
    "            If `fit_amp_phase` is True, these are the best-fit amplitude and \n",
    "            phase of the sinusoids. Otherwise, they are the real and imaginary \n",
    "            amplitudes of the sinusoids.\n",
    "    \"\"\"\n",
    "    # Get shape of data etc.\n",
    "    bandwidth = (freqs[-1] - freqs[0]) / 1e3 # assumed MHz, convert to GHz\n",
    "    assert d.size == invcov.shape[0] == invcov.shape[1] == freqs.size, \\\n",
    "        \"Data, inv. covariance, and freqs array must have same number of channels\"\n",
    "    \n",
    "    # Calculate tau values\n",
    "    if tau is None:\n",
    "        tau = np.fft.fftfreq(n=freqs.size, d=freqs[1]-freqs[0]) * 1e3 # nanosec\n",
    "    \n",
    "    # Taper\n",
    "    if taper is None:\n",
    "        taper = 1.\n",
    "    else:\n",
    "        assert taper.size == freqs.size, \\\n",
    "            \"'taper' must be evaluated at locations given in 'freqs'\"\n",
    "    \n",
    "    # Log-likelihood (or log-posterior) function\n",
    "    def loglike(p, n):\n",
    "        if fit_amp_phase:\n",
    "            m = model_ap(amp=p[0], phase=p[1], tau=tau[n], freqs=freqs)\n",
    "        else:\n",
    "            m = model_aa(A_re=p[0], A_im=p[1], tau=tau[n], freqs=freqs)\n",
    "        \n",
    "        # Calculate residual and log-likelihood\n",
    "        x = taper * (d - m)\n",
    "        logl = 0.5 * np.dot(x.conj(), np.dot(invcov, x))\n",
    "        return logl.real # Result should be real\n",
    "    \n",
    "    # Set appropriate bounds for fits\n",
    "    max_abs = np.max(np.abs(d))\n",
    "    if fit_amp_phase:\n",
    "        bounds = [(-100.*max_abs, 100.*max_abs), (0., 2.*np.pi)]\n",
    "    else:\n",
    "        bounds = [(-1000.*max_abs, 1000.*max_abs), (-1000.*max_abs, 1000.*max_abs)]\n",
    "    \n",
    "    # Do least-squares fit for each tau\n",
    "    param1 = np.zeros(tau.size)\n",
    "    param2 = np.zeros(tau.size)\n",
    "    \n",
    "    for n in range(tau.size):\n",
    "        p0 = np.zeros(2)\n",
    "\n",
    "        # Rough initial guess\n",
    "        if fit_amp_phase:\n",
    "            p0[0] = 0.2 * np.max(np.abs(d))\n",
    "            p0[1] = 0.5 * np.pi\n",
    "        else:\n",
    "            p0[0] = 0.2 * np.max(d.real) # rough guess at amplitude\n",
    "            p0[1] = 0.2 * np.max(d.imag)\n",
    "        \n",
    "        # Least-squares fit for mode n\n",
    "        result = minimize(loglike, p0, args=(n,), \n",
    "                          method=minimize_method, \n",
    "                          bounds=bounds)\n",
    "        param1[n], param2[n] = result.x\n",
    "    \n",
    "    return tau, param1, param2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "98184239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_flagged_channels(w, x):\n",
    "    \"\"\"\n",
    "    Remove flagged channels from a 1D or 2D (square) array. This is \n",
    "    a necessary pre-processing step for LSSA.\n",
    "\n",
    "    Parameters:\n",
    "        w (array_like):\n",
    "            1D array of mask values, where 1 means unmasked and 0 means \n",
    "            masked.\n",
    "        \n",
    "        x (array_like):\n",
    "            1D or square 2D array to remove the masked channels from.\n",
    "\n",
    "    Returns:\n",
    "        xtilde (array_like):\n",
    "            Input array with the flagged channels removed.\n",
    "    \"\"\"\n",
    "    # Check inputs\n",
    "    assert np.shape(x) == (w.size,) or np.shape(x) == (w.size, w.size), \\\n",
    "        \"Input array must have shape (w.size) or (w.size, w.size)\"\n",
    "\n",
    "    # 1D case\n",
    "    if len(x.shape) == 1:\n",
    "        return x[w == 1.]\n",
    "    else:\n",
    "        return x[:,w == 1.][w == 1.,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3246949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal.windows import dpss, kaiser\n",
    "\n",
    "def dpss_fit_modes(d, w, freqs, cov, nmodes=10, alpha=1.,\n",
    "                   minimize_method='L-BFGS-B', taper=None):\n",
    "    r\"\"\"\n",
    "    Perform a weighted DPSS fit to masked complex 1D data.\n",
    "    \n",
    "    The log-likelihood for each DPSS mode takes the assumed form:\n",
    "    \n",
    "    $\\log L_n = \\tilde{x}^\\dagger \\tilde{C}^{-1} \\tilde{x}$\n",
    "    \n",
    "    where $\\tau_n = n / \\Delta \\nu$, $\\Delta \\nu$ is the bandwidth, and \n",
    "    \n",
    "    $x = [d - A f_dpss(n, \\nu))]$.\n",
    "\n",
    "    The tilde denotes vectors/matrices from which the masked channels \n",
    "    (rows/columns) have been removed entirely.\n",
    "    \n",
    "    Parameters:\n",
    "        d (array_like):\n",
    "            Complex data array that has already had flagged channels removed.\n",
    "        \n",
    "        w (array_like):\n",
    "            Flag array, where \n",
    "        \n",
    "        freqs (array_like):\n",
    "            Array of frequency values, in MHz.\n",
    "        \n",
    "        cov (array_like):\n",
    "            Covariance matrix model.\n",
    "        \n",
    "        nmodes (int, optional):\n",
    "            Number of DPSS modes to fit.\n",
    "        \n",
    "        alpha (float, optional):\n",
    "            Bandwidth factor used in the DPSS functions. Higher values are more \n",
    "            concentrated towards the centre of the band.\n",
    "        \n",
    "        taper (array_like, optional):\n",
    "            If specified, multiplies the data and sinusoid model by a taper \n",
    "            function to enforce periodicity. The taper should be evaluated \n",
    "            at the locations specified in `freqs`.\n",
    "        \n",
    "        minimize_method (str, optional):\n",
    "            Which SciPy minimisation method to use. Default: `'L-BFGS-B'`.\n",
    "        \n",
    "    Returns:\n",
    "        param1, param2 (array_like):\n",
    "            If `fit_amp_phase` is True, these are the best-fit amplitude and \n",
    "            phase of the sinusoids. Otherwise, they are the real and imaginary \n",
    "            amplitudes of the sinusoids.\n",
    "    \"\"\"\n",
    "    # Get shape of data etc.\n",
    "    assert d.size == cov.shape[0] == cov.shape[1] == freqs.size == w.size, \\\n",
    "        \"Data, flags, covariance, and freqs arrays must have same number of channels\"\n",
    "    \n",
    "    # Taper\n",
    "    if taper is None:\n",
    "        taper = 1.\n",
    "    else:\n",
    "        assert taper.size == freqs.size, \\\n",
    "            \"'taper' must be evaluated at locations given in 'freqs'\"\n",
    "    \n",
    "    # Precompute DPSS basis functions, shape: (nmodes, nfreqs)\n",
    "    dpss_modes = dpss(freqs.size, \n",
    "                      NW=alpha, \n",
    "                      Kmax=nmodes, \n",
    "                      sym=False)\n",
    "    \n",
    "    # Invert covariance matrix\n",
    "    invcov = np.linalg.inv(cov)\n",
    "    \n",
    "    # Log-likelihood (or log-posterior) function\n",
    "    def loglike(p):\n",
    "        # Real and imaginary coeffs are interleaved\n",
    "        m = p[0::2,np.newaxis]*dpss_modes[:,:] + 1.j*p[1::2,np.newaxis]*dpss_modes[:,:]\n",
    "        m = np.sum(m, axis=0)\n",
    "        \n",
    "        # Calculate residual and log-likelihood\n",
    "        x = taper * w * (d - m)\n",
    "        logl = 0.5 * np.dot(x.conj(), np.dot(invcov, x))\n",
    "        return logl.real # Result should be real\n",
    "            \n",
    "    # Least-squares fit for all modes\n",
    "    p0 = np.zeros(2*nmodes)\n",
    "    result = minimize(loglike, p0, \n",
    "                      method=minimize_method, \n",
    "                      bounds=None)\n",
    "    amps = result.x\n",
    "    return dpss_modes, amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22f130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
